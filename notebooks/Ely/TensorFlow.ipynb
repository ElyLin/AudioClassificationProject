{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65180abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65261586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c751cedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image according to tensorflow's tutorial \n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ba61714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_OptionsDataset element_spec=(TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "#  Set Data_dir to the path you want the dataset to be downloaded to. example \"user/desktop/AudioClassificationProject/Data\"\n",
    "# Download is equal to False by default so set to True to download dataset to desired PATH\n",
    "# set as_supervised to True so when calling the dataset it returns a tuple (features, label)\n",
    "# features will be the images and labels is the class \n",
    "# This ended up fixing the iterator warning that was being outputted before, not sure why \n",
    "\n",
    "\n",
    "\n",
    "ds=tfds.load('mnist',\n",
    "    split='train',\n",
    "    shuffle_files=True,\n",
    "    data_dir='/Users/stephen/Desktop/AudioClassificationProject/Data/',  # set PATH for download \n",
    "    download=True,     # set download to True to download dataset locally \n",
    "    as_supervised=True)   # added so Tuple is returned (features, Label)\n",
    "assert isinstance(ds, tf.data.Dataset)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f7206d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-06 18:37:43.643311: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m3/ywsrz7k170vbk8511l1h_6840000gn/T/ipykernel_50044/2122161271.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mds_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# take a single example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds_sample\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "# iterate over the dataset\n",
    "ds_sample=ds.take(1) # take a single example\n",
    "for example in ds_sample:\n",
    "    print(list(example.keys()))\n",
    "    image = example['image']\n",
    "    label = example['label']\n",
    "    print(image.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d83f2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize dataset\n",
    "#ds, info = tfds.load('mnist', split='train', with_info=True)\n",
    "#tfds.as_dataframe(ds.take(4), info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e265805",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0790dc",
   "metadata": {},
   "source": [
    "how do I load the data into this notebook?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc52187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to create a Dataset object from .image_dataset_from_directory function you must have the dataset downloaded\n",
    "# data_dir will be a string that represents the PATH of the dataset master folder. \n",
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_dir = '/Users/stephen/Desktop/AudioClassificationProject/Data/mnist/3.0.1/mnist-test.tfrecord-00000-of-00001'\n",
    "image_size = (28, 28)\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=image_size,\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8297ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
